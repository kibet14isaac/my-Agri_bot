# -*- coding: utf-8 -*-
"""my agribot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h6s8H9ZnxVlDxS2CjS15Ro866zkYI4Xn
"""

import requests
import json
import os
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import re # For regular expression matching to extract numbers


API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

# API Key (will be provided by the environment, leave as empty string)
API_KEY = "" # The environment automatically provides the API key.

# --- Agricultural Prediction Model (using Pandas and Scikit-learn) ---
# This is a simplified example. In a real-world scenario, you'd use
# larger, more diverse datasets for training.

# Simulate a small dataset for crop yield prediction (e.g., good vs. poor harvest)
# Features: Rainfall (mm), Temperature (Celsius)
# Target: Crop_Yield_Category (0 = Poor, 1 = Good)
data = {
    'Rainfall_mm': [100, 120, 80, 150, 90, 180, 110, 130, 70, 160],
    'Temperature_C': [20, 23, 18, 25, 21, 26, 22, 24, 19, 27],
    'Crop_Yield_Category': [0, 1, 0, 1, 0, 1, 1, 1, 0, 1]
}
df = pd.DataFrame(data)

# Prepare data for Scikit-learn
X = df[['Rainfall_mm', 'Temperature_C']] # Features
y = df['Crop_Yield_Category']           # Target

# Train a simple Logistic Regression model
# In a real application, you would typically split data into train/test sets
# and perform more rigorous model selection and evaluation.
model = LogisticRegression()
model.fit(X, y)

def predict_crop_yield(rainfall, temperature):
    """
    Predicts crop yield category based on rainfall and temperature using the trained model.

    Args:
        rainfall (float): Rainfall in millimeters.
        temperature (float): Temperature in Celsius.

    Returns:
        str: 'Good Harvest' or 'Poor Harvest'.
    """
    try:
        # Create a DataFrame for the single prediction input
        input_data = pd.DataFrame([[rainfall, temperature]], columns=['Rainfall_mm', 'Temperature_C'])
        prediction = model.predict(input_data)[0]

        if prediction == 1:
            return "Good Harvest"
        else:
            return "Poor Harvest"
    except Exception as e:
        return f"Error making prediction: {e}"

# --- End of Agricultural Prediction Model ---


def get_ai_response(chat_history):
    """
    Sends a request to the Gemini API and returns the AI's response.

    Args:
        chat_history (list): A list of message dictionaries representing the conversation history.

    Returns:
        str: The AI's response text, or an error message if the API call fails.
    """
    payload = {
        "contents": chat_history,
        "generationConfig": {
            "responseMimeType": "text/plain" # Explicitly request plain text
        }
    }

    headers = {
        "Content-Type": "application/json"
    }

    try:
        # Construct the full API URL with the API key
        full_api_url = f"{API_URL}?key={API_KEY}"
        response = requests.post(full_api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)

        result = response.json()

        # Check if the response contains valid candidates and content
        if result and 'candidates' in result and len(result['candidates']) > 0 and \
           'content' in result['candidates'][0] and 'parts' in result['candidates'][0]['content'] and \
           len(result['candidates'][0]['content']['parts']) > 0:
            return result['candidates'][0]['content']['parts'][0]['text']
        else:
            return "Error: No valid response received from the AI."

    except requests.exceptions.RequestException as e:
        return f"Error connecting to the API: {e}"
    except json.JSONDecodeError:
        return "Error: Could not decode JSON response from API."
    except Exception as e:
        return f"An unexpected error occurred: {e}"

def main():
    """
    Main function to run the agricultural chatbot.
    Manages the conversation history and user interaction.
    """
    print("ðŸŒ¾ Welcome to the Agricultural Chatbot! ðŸšœ")
    print("Type 'exit' to end the conversation.")
    print("Try asking: 'Predict yield for 150mm rain and 22C temp'")

    # Initialize chat history with system instructions and an opening message
    # The first 'user' role entry acts as a system prompt to define the AI's persona.
    # The subsequent 'model' entry is the AI's initial greeting based on that persona.
    chat_history = [
        {
            "role": "user",
            "parts": [{"text": "You are an expert agricultural assistant. Provide helpful and practical advice on farming, crops, soil, pests, and general agricultural practices. Be concise and informative. If the user asks for crop yield prediction with rainfall and temperature, use your internal prediction model."}]
        },
        {
            "role": "model",
            "parts": [{"text": "Hello! I'm your agricultural AI assistant. How can I help you with your farming questions today?"}]
        }
    ]

    # Print the initial AI greeting
    print(f"\nAI: {chat_history[-1]['parts'][0]['text']}")

    while True:
        user_input = input("\nYou: ").strip()

        if user_input.lower() == 'exit':
            print("Thank you for using the Agricultural Chatbot. Goodbye!")
            break

        if not user_input:
            print("Please type something to get a response.")
            continue

        # --- Check for specific prediction query ---
        # Regex to find numbers that could be rainfall (mm) and temperature (C)
        match = re.search(r'predict yield for (\d+)mm rain and (\d+)C temp', user_input.lower())
        if match:
            try:
                rainfall = float(match.group(1))
                temperature = float(match.group(2))
                print("Using internal model for prediction...")
                prediction_result = predict_crop_yield(rainfall, temperature)
                ai_response = f"Based on your input of {rainfall}mm rainfall and {temperature}Â°C temperature, the predicted outcome is: {prediction_result}."
            except ValueError:
                ai_response = "I couldn't understand the rainfall and temperature values. Please provide numbers."
            except Exception as e:
                ai_response = f"An error occurred during prediction: {e}"
        else:
            # --- General AI conversation ---
            print("AI is thinking...")
            # Add user's message to chat history for general AI
            chat_history.append({"role": "user", "parts": [{"text": user_input}]})
            ai_response = get_ai_response(chat_history)


        # Add AI's response to chat history
        # Only add to history if it's a Gemini API response.
        # For internal model responses, we only add the final composed message.
        if not match: # If it wasn't a prediction query, add the user message and then AI response.
             # chat_history already has user_input from above.
             chat_history.append({"role": "model", "parts": [{"text": ai_response}]})


        print(f"AI: {ai_response}")

if __name__ == "__main__":
    main()

